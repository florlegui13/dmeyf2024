{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Vd-Rfyik62j"
   },
   "source": [
    "# Gradient Boosting Desicion Tree\n",
    "\n",
    "En las clases anteriores, observamos cómo las mejoras en los algoritmos y las optimizaciones pueden generar avances significativos en la ganancia. Ya hemos logrado un progreso considerable con los modelos de Random Forest. Hoy, daremos un paso aún más grande al explorar los modelos que actualmente están obteniendo los mejores resultados en este tipo de dominios.\n",
    "\n",
    "Antes que nada, carguemos el entorno de trabajo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Vhhu79HVkwb5",
    "outputId": "8eb88929-36f0-4b2f-c7dc-92f571d9ba00"
   },
   "outputs": [],
   "source": [
    "%pip install scikit-learn==1.3.2\n",
    "%pip install seaborn==0.13.1\n",
    "%pip install numpy==1.26.4\n",
    "%pip install matplotlib==3.7.1\n",
    "%pip install pandas==2.1.4\n",
    "%pip install lightgbm==4.4.0\n",
    "%pip install optuna==3.6.1\n",
    "%pip install python-dotenv\n",
    "%pip install plotly\n",
    "%pip install ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qf1nO_iukBeT"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Cj-rL6xHlA2u"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit, StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances, plot_slice, plot_contour\n",
    "\n",
    "from time import time\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import pickle\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8jGKjoN1lRho"
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Accedo a variables de entorno\n",
    "dataset_path = os.getenv('DATASET_PATH')\n",
    "dataset_file = os.getenv('DATASET_FILE')\n",
    "ganancia_acierto = 273000\n",
    "costo_estimulo = 7000\n",
    "semillas = [945787,945799,945809,945811,945817]\n",
    "\n",
    "data = pd.read_csv(dataset_path + dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\n",
    "    'cseguro_vida_lag1',\n",
    "    'minversion2_lag1',\n",
    "    'cinversion2_lag1',\n",
    "    'minversion1_dolares_lag1',\n",
    "    'vmr_mpagominimo_delta1',\n",
    "    'Unnamed: 0'\n",
    "], axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "data['clase_ternaria'].fillna('BAJA+2', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TrH9f1L5Umd"
   },
   "source": [
    "Vamos a asignar pesos a las clases. En unos minutos explicaremos las razones detrás de esta decisión. Mientras tanto, pueden aprovechar el código para ajustar el peso de la clase **BAJA+2** según lo deseen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V2awsEXwO5_w"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AlYeDIBQP3-s"
   },
   "outputs": [],
   "source": [
    "data['clase_peso'] = 1.0\n",
    "\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzLIRVs850-I"
   },
   "source": [
    "Además, como se mencionó en la clase pasada, comenzaremos a experimentar con nuevas clases para ajustar el modelo. En particular, sumaremos la clase **BAJA+1**, que es estructuralmente muy similar a **BAJA+2**, para aumentar los casos positivos. Luego, compararemos los resultados obtenidos con los de la clase con la que hemos estado trabajando hasta ahora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KV1meQ5cZ_Sl"
   },
   "outputs": [],
   "source": [
    "data['clase_binaria1'] = np.where(data['clase_ternaria'] == 'BAJA+2', 1, 0)\n",
    "data['clase_binaria2'] = np.where(data['clase_ternaria'] == 'CONTINUA', 0, 1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pTcxuFejUeCl"
   },
   "outputs": [],
   "source": [
    "valores_unicos = data['clase_ternaria'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I7AcBb2aUkNM"
   },
   "outputs": [],
   "source": [
    "print(valores_unicos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5AYJG0r16dW9"
   },
   "source": [
    "Y trabajaremos como es habitual en las últimas clases, con **Febrero** para entrenar y **Abril** para medir, con el fin de realizar *backtesting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1728787406277,
     "user": {
      "displayName": "Florencia Leguizamon",
      "userId": "13676436166589695637"
     },
     "user_tz": 180
    },
    "id": "CVDW-YPNXkXj",
    "outputId": "75a1f7ea-1926-4cc9-9715-66263d80935b"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "executionInfo": {
     "elapsed": 767,
     "status": "error",
     "timestamp": 1731434944412,
     "user": {
      "displayName": "Florencia Leguizamon",
      "userId": "13676436166589695637"
     },
     "user_tz": 180
    },
    "id": "mZ8Qm0vqvF_F",
    "outputId": "b259cdc9-ec45-45e9-b80f-9ef8c5eda04c"
   },
   "outputs": [],
   "source": [
    "#mes_train = 202104\n",
    "mes_test = 202108\n",
    "\n",
    "train_data = data[data['foto_mes'].isin([202104, 202105, 202106])] #Para competencia_02\n",
    "#train_data = data[data['foto_mes'] == mes_train]\n",
    "\n",
    "test_data = data[data['foto_mes'] == mes_test]\n",
    "\n",
    "X_train = train_data.drop(['clase_ternaria', 'clase_peso', 'clase_binaria1','clase_binaria2'], axis=1)\n",
    "y_train_binaria1 = train_data['clase_binaria1']\n",
    "y_train_binaria2 = train_data['clase_binaria2']\n",
    "w_train = train_data['clase_peso']\n",
    "\n",
    "X_test = test_data.drop(['clase_ternaria', 'clase_peso', 'clase_binaria1','clase_binaria2'], axis=1)\n",
    "y_test_binaria1 = test_data['clase_binaria1']\n",
    "y_test_class = test_data['clase_ternaria']\n",
    "w_test = test_data['clase_peso']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1728851384873,
     "user": {
      "displayName": "Florencia Leguizamon",
      "userId": "13676436166589695637"
     },
     "user_tz": 180
    },
    "id": "ww7mMBigS2ld",
    "outputId": "9e75438e-d4d2-45c6-ab04-eeb4a7446bfd"
   },
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1728851384873,
     "user": {
      "displayName": "Florencia Leguizamon",
      "userId": "13676436166589695637"
     },
     "user_tz": 180
    },
    "id": "z-f39CMIS5w_",
    "outputId": "8c45868c-ade1-40b0-8d90-8cb09b958a05"
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scpnp1HJ6wfO"
   },
   "source": [
    "Y preparamos el *dataset* para poder usar el **rf** de una clase anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5cqbDiI4x2OD"
   },
   "outputs": [],
   "source": [
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "Xif = imp_mean.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k31eSe5zlTEk"
   },
   "source": [
    "Comenzaremos explicando el funcionamiento del protagonista de esta clase: **LightGBM**. Primero, partiremos con una revisión de cómo funciona el algoritmo en el que se basa, **XGBoost**. Para una introducción completa, puedes consultar este\n",
    "\n",
    "https://xgboost.readthedocs.io/en/stable/tutorials/model.html.\n",
    "\n",
    "Aunque en la cátedra no somos grandes seguidores de Josh Starmer y su canal *StatQuest*, reconozco que sus series sobre *Gradient Boosting* y *XGBoost* son excelentes recursos. Aquí te dejamos los enlaces a esas dos series que realmente valen la pena:\n",
    "\n",
    "[Serie Gradient Boosting](https://www.youtube.com/watch?v=3CC4N4z3GJc&list=PLblh5JKOoLUJjeXUvUE0maghNuY2_5fY6)\n",
    "\n",
    "[Serie XGBoost](https://www.youtube.com/watch?v=OtD8wVaFm6E&list=PLblh5JKOoLULU0irPgs1SnKO6wqVjKUsQ)\n",
    "\n",
    "Finalmente, analizaremos las diferencias clave que ofrece **LightGBM** frente a XGBoost. Puedes explorar más sobre ello en este https://lightgbm.readthedocs.io/en/stable/Features.html.\n",
    "\n",
    "No olvides tener a mano la [documentación de LightGBM](https://lightgbm.readthedocs.io/)y la [lista completa de sus parámetros](https://lightgbm.readthedocs.io/en/latest/Parameters.html).\n",
    "\n",
    "Este es un algoritmo muy usado en el mercado, recomiendo dedicarle el tiempo necesario para aprenderlo bien."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQ-3AgzL9ude"
   },
   "source": [
    "Vamos a utilizar el algoritmo directamente, sin pasar por *scikit-learn*. Sin embargo, si algún alumno lo prefiere, puede optar por usar el *wrapper* de sklearn para este caso.\n",
    "\n",
    "Para evaluar la calidad del modelo, crearemos nuestra propia función de evaluación que calcule la ganancia. La razón de incluir los pesos es precisamente para poder implementar esta función de evaluación de manera adecuada. Al combinar las clases *BAJA+1* y *BAJA+2* en una sola, necesitamos una forma de diferenciarlas, y es aquí donde entra en juego el *weight*. Este parámetro nos permitirá distinguir entre ambas clases al momento de evaluarlas dentro del algoritmo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_FvDUXeatl66"
   },
   "outputs": [],
   "source": [
    "def lgb_gan_eval(y_pred, data):\n",
    "    weight = data.get_weight()\n",
    "    ganancia = np.where(weight == 1.00002, ganancia_acierto, 0) - np.where(weight < 1.00002, costo_estimulo, 0)\n",
    "    ganancia = ganancia[np.argsort(y_pred)[::-1]]\n",
    "    ganancia = np.cumsum(ganancia)\n",
    "\n",
    "    return 'gan_eval', np.max(ganancia) , True\n",
    "\n",
    "# Parámetros del modelo\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'gan_eval',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'max_bin': 31,\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.3,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qte_kOcU-7i3"
   },
   "source": [
    "LGBM necesita su propio tipo de Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5dnWsRWgPnRr"
   },
   "outputs": [],
   "source": [
    "train_data1 = lgb.Dataset(X_train, label=y_train_binaria1, weight=w_train)\n",
    "train_data2 = lgb.Dataset(X_train, label=y_train_binaria2, weight=w_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GSEwNi3_IxN"
   },
   "source": [
    "A continuación, compararemos las dos clases. Utilizaremos para medir la calidad de las clases (y de los parámetros), la función **cv** que viene *out-of-the-box*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 181642,
     "status": "ok",
     "timestamp": 1728851572609,
     "user": {
      "displayName": "Florencia Leguizamon",
      "userId": "13676436166589695637"
     },
     "user_tz": 180
    },
    "id": "ibXn1tiLNT6J",
    "outputId": "cb63bed4-5596-49e0-c42a-48ab0873b01e"
   },
   "outputs": [],
   "source": [
    "cv_results1 = lgb.cv(\n",
    "    params,\n",
    "    train_data1,\n",
    "    num_boost_round=150,\n",
    "    feval=lgb_gan_eval,\n",
    "    nfold=5,\n",
    "    seed=semillas[0]\n",
    ")\n",
    "\n",
    "cv_results2 = lgb.cv(\n",
    "    params,\n",
    "    train_data2,\n",
    "    num_boost_round=150,\n",
    "    feval=lgb_gan_eval,\n",
    "    nfold=5,\n",
    "    seed=semillas[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ePRPrDL8_odf"
   },
   "source": [
    "Y vizualizamos los resultados de ambas ejecuciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1728851573104,
     "user": {
      "displayName": "Florencia Leguizamon",
      "userId": "13676436166589695637"
     },
     "user_tz": 180
    },
    "id": "cOoWx9sbhx5h",
    "outputId": "06039cf1-a608-4d63-9f6a-3fefc85577cb"
   },
   "outputs": [],
   "source": [
    "df_ganancias = pd.DataFrame({\n",
    "    'binaria1': cv_results1['valid gan_eval-mean'],\n",
    "    'binaria2': cv_results2['valid gan_eval-mean'],\n",
    "    'Iteracion': range(1, len(cv_results1['valid gan_eval-mean']) + 1)\n",
    "})\n",
    "\n",
    "# Normalizamos la ganancias\n",
    "df_ganancias['binaria1'] = df_ganancias['binaria1']*5\n",
    "df_ganancias['binaria2'] = df_ganancias['binaria2']*5\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x='Iteracion', y='binaria1', data=df_ganancias, label='binaria 1')\n",
    "sns.lineplot(x='Iteracion', y='binaria2', data=df_ganancias, label='binaria 2')\n",
    "plt.title('Comparación de las Ganancias de las 2 clases binarias')\n",
    "plt.xlabel('Iteración')\n",
    "plt.ylabel('Ganancia')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N96lUJOLDqLH"
   },
   "source": [
    "Se observa una ligera mejora al combinar las clases en modelos sencillos. Dado que cada pequeña mejora es importante, continuaremos utilizando esta estrategia.\n",
    "\n",
    "A continuación, procederemos a optimizar **LightGBM** utilizando la librería **Optuna**. Cabe destacar que las optimizaciones que realizaremos son básicas y están diseñadas para ejecutarse en pocos minutos. Será su responsabilidad ampliar tanto el rango de búsqueda como el tiempo de optimización para obtener un modelo más competitivo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1416,
     "status": "ok",
     "timestamp": 1728851574513,
     "user": {
      "displayName": "Florencia Leguizamon",
      "userId": "13676436166589695637"
     },
     "user_tz": 180
    },
    "id": "bYMEnNFbkSoQ",
    "outputId": "bd466833-17f2-4bc8-a27f-250ae737c7aa"
   },
   "outputs": [],
   "source": [
    "\n",
    "def objective(trial):\n",
    "\n",
    "    num_leaves = trial.suggest_int('num_leaves', 8, 100),\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.005, 0.3), # mas bajo, más iteraciones necesita\n",
    "    min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 1, 1000),\n",
    "    feature_fraction = trial.suggest_float('feature_fraction', 0.1, 1.0),\n",
    "    bagging_fraction = trial.suggest_float('bagging_fraction', 0.1, 1.0),\n",
    "\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'custom',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'first_metric_only': True,\n",
    "        'boost_from_average': True,\n",
    "        'feature_pre_filter': False,\n",
    "        'max_bin': 31,\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': learning_rate,\n",
    "        'min_data_in_leaf': min_data_in_leaf,\n",
    "        'feature_fraction': feature_fraction,\n",
    "        'bagging_fraction': bagging_fraction,\n",
    "        'seed': semillas[0],\n",
    "        'verbose': -1\n",
    "    }\n",
    "    train_data = lgb.Dataset(X_train,\n",
    "                              label=y_train_binaria2, # eligir la clase\n",
    "                              weight=w_train)\n",
    "    cv_results = lgb.cv(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=100, # modificar, subit y subir... y descomentar la línea inferior\n",
    "        # early_stopping_rounds= int(50 + 5 / learning_rate),\n",
    "        feval=lgb_gan_eval,\n",
    "        stratified=True,\n",
    "        nfold=5,\n",
    "        seed=semillas[0]\n",
    "    )\n",
    "    max_gan = max(cv_results['valid gan_eval-mean'])\n",
    "    best_iter = cv_results['valid gan_eval-mean'].index(max_gan) + 1\n",
    "\n",
    "    # Guardamos cual es la mejor iteración del modelo\n",
    "    trial.set_user_attr(\"best_iter\", best_iter)\n",
    "\n",
    "    return max_gan * 5\n",
    "\n",
    "\n",
    "storage_name = \"sqlite:///\" + dataset_path + \"optimization_lgbm.db\"\n",
    "study_name = \"exp_301_lgbm\"\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 764
    },
    "executionInfo": {
     "elapsed": 59699,
     "status": "error",
     "timestamp": 1728851980029,
     "user": {
      "displayName": "Florencia Leguizamon",
      "userId": "13676436166589695637"
     },
     "user_tz": 180
    },
    "id": "-DI7zXUryMw4",
    "outputId": "3d6833fd-f5ac-44ce-cd26-041378e64419"
   },
   "outputs": [],
   "source": [
    "new_var = study.optimize(objective, n_trials=100) # Ajustar a 1000 en gcloud\n",
    "new_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ia2vN07FEasX"
   },
   "source": [
    "Analizamos los resultados as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 959,
     "status": "ok",
     "timestamp": 1728791054974,
     "user": {
      "displayName": "Florencia Leguizamon",
      "userId": "13676436166589695637"
     },
     "user_tz": 180
    },
    "id": "fH4ybQgYx7Xf",
    "outputId": "d4444bd2-ea56-436a-cc27-2c2cb40ab2ce"
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 171038,
     "status": "ok",
     "timestamp": 1728791226008,
     "user": {
      "displayName": "Florencia Leguizamon",
      "userId": "13676436166589695637"
     },
     "user_tz": 180
    },
    "id": "vOfm5DXAx8Rj",
    "outputId": "6d284613-858d-49a1-abe7-38c170665220"
   },
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0Z-r8QYEsNN"
   },
   "source": [
    "El **learning rate** es un parámetro que tiene que ir acompañado por más árboles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 2022,
     "status": "ok",
     "timestamp": 1728791228026,
     "user": {
      "displayName": "Florencia Leguizamon",
      "userId": "13676436166589695637"
     },
     "user_tz": 180
    },
    "id": "0U6CfznSx-gG",
    "outputId": "36d35da6-c23c-435c-d56e-60249687ed2f"
   },
   "outputs": [],
   "source": [
    "plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "XRqPgCD6yB_q",
    "outputId": "f443373c-95ce-4ca4-f93f-f3dab6ccf819"
   },
   "outputs": [],
   "source": [
    "plot_contour(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "wGHGdGcQ3m00",
    "outputId": "a3dd064d-45b6-4f27-99aa-ad4a334e4790"
   },
   "outputs": [],
   "source": [
    "plot_contour(study, params=['num_leaves','min_data_in_leaf'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjgD6raVE6am"
   },
   "source": [
    "Y finalmente tomamos el mejor modelo y lo entrenamos con la totalidad de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "bwyUriQksZAM",
    "outputId": "b0c6be8c-f7b0-415b-f059-1b7c5d0ca644"
   },
   "outputs": [],
   "source": [
    "best_iter = study.best_trial.user_attrs[\"best_iter\"]\n",
    "print(f\"Mejor cantidad de árboles para el mejor model {best_iter}\")\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'first_metric_only': True,\n",
    "    'boost_from_average': True,\n",
    "    'feature_pre_filter': False,\n",
    "    'max_bin': 31,\n",
    "    'num_leaves': study.best_trial.params['num_leaves'],\n",
    "    'learning_rate': study.best_trial.params['learning_rate'],\n",
    "    'min_data_in_leaf': study.best_trial.params['min_data_in_leaf'],\n",
    "    'feature_fraction': study.best_trial.params['feature_fraction'],\n",
    "    'bagging_fraction': study.best_trial.params['bagging_fraction'],\n",
    "    'seed': semillas[0],\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "train_data = lgb.Dataset(X_train,\n",
    "                          label=y_train_binaria2,\n",
    "                          weight=w_train)\n",
    "\n",
    "model = lgb.train(params,\n",
    "                  train_data,\n",
    "                  num_boost_round=best_iter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOyqa5mbFySM"
   },
   "source": [
    "Observamos la variables más importantes para el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "xUejb7eutd0i",
    "outputId": "8c4e9045-295d-4178-ad04-8bee3df194b5"
   },
   "outputs": [],
   "source": [
    "lgb.plot_importance(model, figsize=(10, 20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LkTH9daXF5tp"
   },
   "source": [
    "Y si queremos tener las variables más importantes en forma de *Dataframe*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "l7ZObpkHtnUl",
    "outputId": "aa778ea0-d954-45e2-f1c9-a3b10866b8a6"
   },
   "outputs": [],
   "source": [
    "importances = model.feature_importance()\n",
    "feature_names = X_train.columns.tolist()\n",
    "importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "importance_df = importance_df.sort_values('importance', ascending=False)\n",
    "importance_df[importance_df['importance'] > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opcional: guardo modelo como txt\n",
    "\n",
    "# model.save_model(modelos_path + 'lgb_first.txt')\n",
    "# model = lgb.Booster(model_file=modelos_path + 'lgb_first.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Bac1TlkZjuqE"
   },
   "outputs": [],
   "source": [
    "y_pred_lgm = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "0rx7LaiWjwNp",
    "outputId": "647ae0b1-5cf6-4b87-add9-a14857fb9af7"
   },
   "outputs": [],
   "source": [
    "print(y_pred_lgm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "iKcXUhCHlywR",
    "outputId": "cc34bc9a-be57-443c-f54f-14e585072c01"
   },
   "outputs": [],
   "source": [
    "# Supongamos que 'X_test' es tu DataFrame original del que deseas conservar el resto\n",
    "y_pred_prob = model.predict(X_test)\n",
    "\n",
    "# Convertir a predicciones binarias usando un umbral de 0.025\n",
    "threshold = 0.025\n",
    "y_pred_binary = (y_pred_prob >= threshold).astype(int)\n",
    "\n",
    "# Agregar las columnas de probabilidades y predicciones al DataFrame original\n",
    "X_test['probabilidad'] = y_pred_prob\n",
    "X_test['prediccion'] = y_pred_binary\n",
    "\n",
    "# Ver las primeras filas del DataFrame original con las nuevas columnas\n",
    "print(X_test.head(20))  # Muestra las primeras 20 filas\n",
    "\n",
    "# Ver las ultimas filas\n",
    "print(X_test.tail(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "mqUhlfgGnbmU",
    "outputId": "fb6fb327-be2a-453c-915c-ac82cc0f5cb0"
   },
   "outputs": [],
   "source": [
    "X_test.prediccion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "6llnHQxNoTEF",
    "outputId": "e2771427-0dd1-47ad-e6c4-e501efdd3f7f"
   },
   "outputs": [],
   "source": [
    "# Filtrar el DataFrame para quedarte solo con 'numero_de_cliente' y 'prediccion'\n",
    "result_df = X_test[['numero_de_cliente', 'prediccion']]\n",
    "\n",
    "# Renombrar la columna 'prediccion' a 'Predicted' si es necesario\n",
    "result_df.rename(columns={'prediccion': 'Predicted'}, inplace=True)\n",
    "\n",
    "# Ver las primeras filas del DataFrame resultante\n",
    "print(result_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "HFD46lIRpa0F"
   },
   "outputs": [],
   "source": [
    "# Especificar la ruta completa del archivo donde deseas guardar el DataFrame\n",
    "fecha_actual = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "output_file = dataset_path + \"resultados_predicciones\" + fecha_actual + \".csv\"\n",
    "\n",
    "# Guardar el DataFrame como un archivo CSV en la ruta especificada\n",
    "result_df.to_csv(output_file, index=False)\n",
    "\n",
    "\n",
    "# Y esto? Estaba en el collab\n",
    "# y_pred_rf = model_rf_1000.predict_proba(Xif)\n",
    "# y_pred_rf = y_pred_rf[:,1] # adaptamos la salida para que sea homogénea con el LGBM\n",
    "# y_pred_lgm = model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
