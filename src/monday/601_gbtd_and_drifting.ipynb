{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Vhhu79HVkwb5",
    "outputId": "8eb88929-36f0-4b2f-c7dc-92f571d9ba00"
   },
   "outputs": [],
   "source": [
    "%pip install scikit-learn==1.3.2\n",
    "%pip install seaborn==0.13.1\n",
    "%pip install numpy==1.26.4\n",
    "%pip install matplotlib==3.7.1\n",
    "%pip install pandas==2.1.4\n",
    "%pip install lightgbm==4.4.0\n",
    "%pip install optuna==3.6.1\n",
    "%pip install python-dotenv\n",
    "%pip install plotly\n",
    "%pip install ipython\n",
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Cj-rL6xHlA2u"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit, StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances, plot_slice, plot_contour\n",
    "\n",
    "from time import time\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import pickle\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8jGKjoN1lRho"
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Accedo a variables de entorno\n",
    "dataset_path = os.getenv('DATASET_PATH')\n",
    "dataset_file = os.getenv('DATASET_FILE')\n",
    "mes_test = int(os.getenv('MES_TEST'))\n",
    "trials = int(os.getenv('TRIALS'))\n",
    "\n",
    "ganancia_acierto = 273000\n",
    "costo_estimulo = 7000\n",
    "semillas = [945787,945799,945809,945811,945817]\n",
    "\n",
    "data = pd.read_csv(dataset_path + dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mpayroll_sobre_edad'] = data['mpayroll'] / data['cliente_edad']\n",
    "\n",
    "# Variables de sumas\n",
    "data['vm_mfinanciacion_limite'] = data[['Master_mfinanciacion_limite', 'Visa_mfinanciacion_limite']].sum(axis=1, skipna=True)\n",
    "data['vm_Fvencimiento'] = data[['Master_Fvencimiento', 'Visa_Fvencimiento']].min(axis=1, skipna=True)\n",
    "data['vm_Finiciomora'] = data[['Master_Finiciomora', 'Visa_Finiciomora']].min(axis=1, skipna=True)\n",
    "data['vm_msaldototal'] = data[['Master_msaldototal', 'Visa_msaldototal']].sum(axis=1, skipna=True)\n",
    "data['vm_msaldopesos'] = data[['Master_msaldopesos', 'Visa_msaldopesos']].sum(axis=1, skipna=True)\n",
    "data['vm_msaldodolares'] = data[['Master_msaldodolares', 'Visa_msaldodolares']].sum(axis=1, skipna=True)\n",
    "data['vm_mconsumospesos'] = data[['Master_mconsumospesos', 'Visa_mconsumospesos']].sum(axis=1, skipna=True)\n",
    "data['vm_mconsumosdolares'] = data[['Master_mconsumosdolares', 'Visa_mconsumosdolares']].sum(axis=1, skipna=True)\n",
    "data['vm_mlimitecompra'] = data[['Master_mlimitecompra', 'Visa_mlimitecompra']].sum(axis=1, skipna=True)\n",
    "data['vm_madelantopesos'] = data[['Master_madelantopesos', 'Visa_madelantopesos']].sum(axis=1, skipna=True)\n",
    "data['vm_madelantodolares'] = data[['Master_madelantodolares', 'Visa_madelantodolares']].sum(axis=1, skipna=True)\n",
    "data['vm_fultimo_cierre'] = data[['Master_fultimo_cierre', 'Visa_fultimo_cierre']].max(axis=1, skipna=True)\n",
    "data['vm_mpagado'] = data[['Master_mpagado', 'Visa_mpagado']].sum(axis=1, skipna=True)\n",
    "data['vm_mpagospesos'] = data[['Master_mpagospesos', 'Visa_mpagospesos']].sum(axis=1, skipna=True)\n",
    "data['vm_mpagosdolares'] = data[['Master_mpagosdolares', 'Visa_mpagosdolares']].sum(axis=1, skipna=True)\n",
    "data['vm_fechaalta'] = data[['Master_fechaalta', 'Visa_fechaalta']].max(axis=1, skipna=True)\n",
    "data['vm_mconsumototal'] = data[['Master_mconsumototal', 'Visa_mconsumototal']].sum(axis=1, skipna=True)\n",
    "data['vm_cconsumos'] = data[['Master_cconsumos', 'Visa_cconsumos']].sum(axis=1, skipna=True)\n",
    "data['vm_cadelantosefectivo'] = data[['Master_cadelantosefectivo', 'Visa_cadelantosefectivo']].sum(axis=1, skipna=True)\n",
    "data['vm_mpagominimo'] = data[['Master_mpagominimo', 'Visa_mpagominimo']].sum(axis=1, skipna=True)\n",
    "\n",
    "# Variables de ratios\n",
    "data['vmr_Master_mlimitecompra'] = data['Master_mlimitecompra'] / data['vm_mlimitecompra']\n",
    "data['vmr_Visa_mlimitecompra'] = data['Visa_mlimitecompra'] / data['vm_mlimitecompra']\n",
    "data['vmr_msaldototal'] = data['vm_msaldototal'] / data['vm_mlimitecompra']\n",
    "data['vmr_msaldopesos'] = data['vm_msaldopesos'] / data['vm_mlimitecompra']\n",
    "data['vmr_msaldopesos2'] = data['vm_msaldopesos'] / data['vm_msaldototal']\n",
    "data['vmr_msaldodolares'] = data['vm_msaldodolares'] / data['vm_mlimitecompra']\n",
    "data['vmr_msaldodolares2'] = data['vm_msaldodolares'] / data['vm_msaldototal']\n",
    "data['vmr_mconsumospesos'] = data['vm_mconsumospesos'] / data['vm_mlimitecompra']\n",
    "data['vmr_mconsumosdolares'] = data['vm_mconsumosdolares'] / data['vm_mlimitecompra']\n",
    "data['vmr_madelantopesos'] = data['vm_madelantopesos'] / data['vm_mlimitecompra']\n",
    "data['vmr_madelantodolares'] = data['vm_madelantodolares'] / data['vm_mlimitecompra']\n",
    "data['vmr_mpagado'] = data['vm_mpagado'] / data['vm_mlimitecompra']\n",
    "data['vmr_mpagospesos'] = data['vm_mpagospesos'] / data['vm_mlimitecompra']\n",
    "data['vmr_mpagosdolares'] = data['vm_mpagosdolares'] / data['vm_mlimitecompra']\n",
    "data['vmr_mconsumototal'] = data['vm_mconsumototal'] / data['vm_mlimitecompra']\n",
    "data['vmr_mpagominimo'] = data['vm_mpagominimo'] / data['vm_mlimitecompra']\n",
    "\n",
    "\n",
    "\n",
    "# Filtramos solo las columnas numéricas\n",
    "numeric_cols = data.select_dtypes(include=[np.number])\n",
    "\n",
    "# Reemplazo valores infinitos con NaN solo en las columnas numéricas\n",
    "infinitos_qty = np.isinf(numeric_cols).sum().sum()\n",
    "if infinitos_qty > 0:\n",
    "    print(f\"ATENCIÓN: Hay {infinitos_qty} valores infinitos en tu dataset. Serán pasados a NaN.\")\n",
    "    data[numeric_cols.columns] = numeric_cols.replace([np.inf, -np.inf], np.nan)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_count_by_month = data.groupby('foto_mes').apply(lambda df: df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar columnas con al menos un valor distinto de 0\n",
    "filtered_columns = null_count_by_month.loc[:, (null_count_by_month != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import median_abs_deviation\n",
    "\n",
    "# Calcular la mediana y la desviación absoluta de la mediana (MAD) por columna\n",
    "median_values = filtered_columns.median()\n",
    "mad_values = filtered_columns.apply(median_abs_deviation)\n",
    "\n",
    "# Identificar columnas donde alguna fila supera 3 veces la MAD\n",
    "columns_with_outliers = filtered_columns.loc[:, ((filtered_columns - median_values).abs() > (3 * mad_values)).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_with_outliers.to_excel('columns_with_outliers.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Directorio actual:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "data.drop([\n",
    "    'cseguro_vida_lag1',\n",
    "    'minversion2_lag1',\n",
    "    'cinversion2_lag1',\n",
    "    'minversion1_dolares_lag1',\n",
    "    'vmr_mpagominimo_delta1',\n",
    "    'Unnamed: 0'\n",
    "], axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "# Asigno nan a la columna clase_ternaria si foto_mes es igual a mes_test\n",
    "data.loc[data['foto_mes'] == mes_test, 'clase_ternaria'] = np.nan\n",
    "'''\n",
    "data.drop([\n",
    "    'Unnamed: 0'\n",
    "], axis=1, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V2awsEXwO5_w"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AlYeDIBQP3-s"
   },
   "outputs": [],
   "source": [
    "data['clase_peso'] = 1.0\n",
    "\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KV1meQ5cZ_Sl"
   },
   "outputs": [],
   "source": [
    "data['clase_binaria1'] = np.where(data['clase_ternaria'] == 'BAJA+2', 1, 0)\n",
    "data['clase_binaria2'] = np.where(data['clase_ternaria'] == 'CONTINUA', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pTcxuFejUeCl"
   },
   "outputs": [],
   "source": [
    "valores_unicos = data['clase_ternaria'].unique()\n",
    "print(valores_unicos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1728787406277,
     "user": {
      "displayName": "Florencia Leguizamon",
      "userId": "13676436166589695637"
     },
     "user_tz": 180
    },
    "id": "CVDW-YPNXkXj",
    "outputId": "75a1f7ea-1926-4cc9-9715-66263d80935b"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino dataset de train y dataset de test\n",
    "\n",
    "train_data = data[(data['foto_mes'] != mes_test) & (data['foto_mes'] != mes_test - 1)]\n",
    "#train_data = data[data['foto_mes'].isin([202101, 202102, 202103])]\n",
    "\n",
    "test_data = data[data['foto_mes'] == mes_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Inicia drifting\n",
    "\n",
    "train_null_percentage = train_data.isnull().mean() * 100\n",
    "test_null_percentage = test_data.isnull().mean() * 100\n",
    "\n",
    "comparison_df = pd.DataFrame({'Train Null Percentage': train_null_percentage, 'Score Null Percentage': test_null_percentage})\n",
    "comparison_df['diff_nulls'] = (comparison_df['Score Null Percentage'] - comparison_df['Train Null Percentage']).abs()\n",
    "\n",
    "comparison_df_sorted = comparison_df.sort_values('diff_nulls', ascending=False)\n",
    "\n",
    "comparison_df_sorted\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "trial_null_df_sorted = comparison_df.sort_values('Train Null Percentage', ascending=False)\n",
    "\n",
    "trial_null_df_sorted\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "train_zero_percentage = (train_data == 0).mean() * 100\n",
    "score_zero_percentage = (test_data == 0).mean() * 100\n",
    "\n",
    "comparison_df_zero = pd.DataFrame({'Train Zero Percentage': train_zero_percentage, 'Score Zero Percentage': score_zero_percentage})\n",
    "\n",
    "comparison_df_zero['diff_zero_percentage'] = (comparison_df_zero['Score Zero Percentage'] - comparison_df_zero['Train Zero Percentage']).abs()\n",
    "diff_zero_percentage_sorted = comparison_df_zero.sort_values('diff_zero_percentage',ascending=False)\n",
    "diff_zero_percentage_sorted\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "diff_trial_zero_percentage_sorted = comparison_df_zero.sort_values('Train Zero Percentage', ascending=False)\n",
    "diff_trial_zero_percentage_sorted\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "columnas_a_eliminar = list(set(\n",
    "    comparison_df_sorted[comparison_df_sorted['diff_nulls'] > 5].index\n",
    ").union(\n",
    "    diff_zero_percentage_sorted[diff_zero_percentage_sorted['diff_zero_percentage'] > 5].index\n",
    "))\n",
    "\n",
    "\n",
    "columnas_a_saltar = {'clase_binaria2', 'clase_binaria1','clase_ternaria','foto_mes'}\n",
    "columnas_a_eliminar = [col for col in columnas_a_eliminar if col not in columnas_a_saltar]\n",
    "\n",
    "\n",
    "train_data = train_data.drop(columns=columnas_a_eliminar)\n",
    "test_data = test_data.drop(columns=columnas_a_eliminar)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "columnas_a_eliminar = list(set(\n",
    "    trial_null_df_sorted[trial_null_df_sorted['Train Null Percentage'] > 90].index\n",
    ").union(\n",
    "    diff_trial_zero_percentage_sorted[diff_trial_zero_percentage_sorted[\"Train Zero Percentage\"] > 90].index\n",
    "))\n",
    "\n",
    "columnas_a_eliminar = [col for col in columnas_a_eliminar if col not in columnas_a_saltar]\n",
    "\n",
    "train_data = train_data.drop(columns=columnas_a_eliminar)\n",
    "test_data = test_data.drop(columns=columnas_a_eliminar)\n",
    "\n",
    "# Termina drifting\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "executionInfo": {
     "elapsed": 767,
     "status": "error",
     "timestamp": 1731434944412,
     "user": {
      "displayName": "Florencia Leguizamon",
      "userId": "13676436166589695637"
     },
     "user_tz": 180
    },
    "id": "mZ8Qm0vqvF_F",
    "outputId": "b259cdc9-ec45-45e9-b80f-9ef8c5eda04c"
   },
   "outputs": [],
   "source": [
    "X_train = train_data.drop(['clase_ternaria', 'clase_peso', 'clase_binaria1','clase_binaria2'], axis=1)\n",
    "y_train_binaria1 = train_data['clase_binaria1']\n",
    "y_train_binaria2 = train_data['clase_binaria2']\n",
    "w_train = train_data['clase_peso']\n",
    "\n",
    "X_test = test_data.drop(['clase_ternaria', 'clase_peso', 'clase_binaria1','clase_binaria2'], axis=1)\n",
    "y_test_binaria1 = test_data['clase_binaria1']\n",
    "y_test_class = test_data['clase_ternaria']\n",
    "w_test = test_data['clase_peso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5cqbDiI4x2OD"
   },
   "outputs": [],
   "source": [
    "#imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "#Xif = imp_mean.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_FvDUXeatl66"
   },
   "outputs": [],
   "source": [
    "def lgb_gan_eval(y_pred, data):\n",
    "    weight = data.get_weight()\n",
    "    ganancia = np.where(weight == 1.00002, ganancia_acierto, 0) - np.where(weight < 1.00002, costo_estimulo, 0)\n",
    "    ganancia = ganancia[np.argsort(y_pred)[::-1]]\n",
    "    ganancia = np.cumsum(ganancia)\n",
    "\n",
    "    return 'gan_eval', np.max(ganancia) , True\n",
    "\n",
    "# Parámetros del modelo\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'gan_eval',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'max_bin': 31,\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.3,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5dnWsRWgPnRr"
   },
   "outputs": [],
   "source": [
    "train_data1 = lgb.Dataset(X_train, label=y_train_binaria1, weight=w_train)\n",
    "train_data2 = lgb.Dataset(X_train, label=y_train_binaria2, weight=w_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 181642,
     "status": "ok",
     "timestamp": 1728851572609,
     "user": {
      "displayName": "Florencia Leguizamon",
      "userId": "13676436166589695637"
     },
     "user_tz": 180
    },
    "id": "ibXn1tiLNT6J",
    "outputId": "cb63bed4-5596-49e0-c42a-48ab0873b01e"
   },
   "outputs": [],
   "source": [
    "cv_results1 = lgb.cv(\n",
    "    params,\n",
    "    train_data1,\n",
    "    num_boost_round=150,\n",
    "    feval=lgb_gan_eval,\n",
    "    nfold=5,\n",
    "    seed=semillas[0]\n",
    ")\n",
    "\n",
    "cv_results2 = lgb.cv(\n",
    "    params,\n",
    "    train_data2,\n",
    "    num_boost_round=150,\n",
    "    feval=lgb_gan_eval,\n",
    "    nfold=5,\n",
    "    seed=semillas[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1728851573104,
     "user": {
      "displayName": "Florencia Leguizamon",
      "userId": "13676436166589695637"
     },
     "user_tz": 180
    },
    "id": "cOoWx9sbhx5h",
    "outputId": "06039cf1-a608-4d63-9f6a-3fefc85577cb"
   },
   "outputs": [],
   "source": [
    "df_ganancias = pd.DataFrame({\n",
    "    'binaria1': cv_results1['valid gan_eval-mean'],\n",
    "    'binaria2': cv_results2['valid gan_eval-mean'],\n",
    "    'Iteracion': range(1, len(cv_results1['valid gan_eval-mean']) + 1)\n",
    "})\n",
    "\n",
    "# Normalizamos la ganancias\n",
    "df_ganancias['binaria1'] = df_ganancias['binaria1']*5\n",
    "df_ganancias['binaria2'] = df_ganancias['binaria2']*5\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x='Iteracion', y='binaria1', data=df_ganancias, label='binaria 1')\n",
    "sns.lineplot(x='Iteracion', y='binaria2', data=df_ganancias, label='binaria 2')\n",
    "plt.title('Comparación de las Ganancias de las 2 clases binarias')\n",
    "plt.xlabel('Iteración')\n",
    "plt.ylabel('Ganancia')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1416,
     "status": "ok",
     "timestamp": 1728851574513,
     "user": {
      "displayName": "Florencia Leguizamon",
      "userId": "13676436166589695637"
     },
     "user_tz": 180
    },
    "id": "bYMEnNFbkSoQ",
    "outputId": "bd466833-17f2-4bc8-a27f-250ae737c7aa"
   },
   "outputs": [],
   "source": [
    "\n",
    "def objective(trial):\n",
    "    num_leaves = trial.suggest_int('num_leaves', 8, 100),\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.005, 0.3), # mas bajo, más iteraciones necesita\n",
    "    min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 1, 1000),\n",
    "    feature_fraction = trial.suggest_float('feature_fraction', 0.1, 1.0),\n",
    "    bagging_fraction = trial.suggest_float('bagging_fraction', 0.1, 1.0),\n",
    "\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'custom',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'first_metric_only': True,\n",
    "        'boost_from_average': True,\n",
    "        'feature_pre_filter': False,\n",
    "        'max_bin': 31,\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': learning_rate,\n",
    "        'min_data_in_leaf': min_data_in_leaf,\n",
    "        'feature_fraction': feature_fraction,\n",
    "        'bagging_fraction': bagging_fraction,\n",
    "        'seed': semillas[0],\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train,\n",
    "                              label=y_train_binaria2, # eligir la clase\n",
    "                              weight=w_train)\n",
    "    cv_results = lgb.cv(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=100, # modificar, subit y subir... y descomentar la línea inferior\n",
    "        # early_stopping_rounds= int(50 + 5 / learning_rate),\n",
    "        feval=lgb_gan_eval,\n",
    "        stratified=True,\n",
    "        nfold=5,\n",
    "        seed=semillas[0]\n",
    "    )\n",
    "    max_gan = max(cv_results['valid gan_eval-mean'])\n",
    "    best_iter = cv_results['valid gan_eval-mean'].index(max_gan) + 1\n",
    "\n",
    "    # Guardamos cual es la mejor iteración del modelo\n",
    "    trial.set_user_attr(\"best_iter\", best_iter)\n",
    "\n",
    "    return max_gan * 5\n",
    "\n",
    "\n",
    "now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "storage_name = \"sqlite:///\" + dataset_path + \"optimization_lgbm\" + now + \".db\"\n",
    "study_name = \"exp_301_lgbm\"\n",
    "\n",
    "print('storage_name', storage_name)\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 764
    },
    "executionInfo": {
     "elapsed": 59699,
     "status": "error",
     "timestamp": 1728851980029,
     "user": {
      "displayName": "Florencia Leguizamon",
      "userId": "13676436166589695637"
     },
     "user_tz": 180
    },
    "id": "-DI7zXUryMw4",
    "outputId": "3d6833fd-f5ac-44ce-cd26-041378e64419"
   },
   "outputs": [],
   "source": [
    "new_var = study.optimize(objective, n_trials=trials) # Ajustar a 500 en gcloud\n",
    "new_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 959,
     "status": "ok",
     "timestamp": 1728791054974,
     "user": {
      "displayName": "Florencia Leguizamon",
      "userId": "13676436166589695637"
     },
     "user_tz": 180
    },
    "id": "fH4ybQgYx7Xf",
    "outputId": "d4444bd2-ea56-436a-cc27-2c2cb40ab2ce"
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 171038,
     "status": "ok",
     "timestamp": 1728791226008,
     "user": {
      "displayName": "Florencia Leguizamon",
      "userId": "13676436166589695637"
     },
     "user_tz": 180
    },
    "id": "vOfm5DXAx8Rj",
    "outputId": "6d284613-858d-49a1-abe7-38c170665220"
   },
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 2022,
     "status": "ok",
     "timestamp": 1728791228026,
     "user": {
      "displayName": "Florencia Leguizamon",
      "userId": "13676436166589695637"
     },
     "user_tz": 180
    },
    "id": "0U6CfznSx-gG",
    "outputId": "36d35da6-c23c-435c-d56e-60249687ed2f"
   },
   "outputs": [],
   "source": [
    "plot_slice(study)\n",
    "\n",
    "plot_contour(study, params=['num_leaves','min_data_in_leaf'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "bwyUriQksZAM",
    "outputId": "b0c6be8c-f7b0-415b-f059-1b7c5d0ca644"
   },
   "outputs": [],
   "source": [
    "best_iter = study.best_trial.user_attrs[\"best_iter\"]\n",
    "print(f\"Mejor cantidad de árboles para el mejor model {best_iter}\")\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'first_metric_only': True,\n",
    "    'boost_from_average': True,\n",
    "    'feature_pre_filter': False,\n",
    "    'max_bin': 31,\n",
    "    'num_leaves': study.best_trial.params['num_leaves'],\n",
    "    'learning_rate': study.best_trial.params['learning_rate'],\n",
    "    'min_data_in_leaf': study.best_trial.params['min_data_in_leaf'],\n",
    "    'feature_fraction': study.best_trial.params['feature_fraction'],\n",
    "    'bagging_fraction': study.best_trial.params['bagging_fraction'],\n",
    "    'seed': semillas[0],\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "train_data = lgb.Dataset(X_train,\n",
    "                          label=y_train_binaria2,\n",
    "                          weight=w_train)\n",
    "\n",
    "model = lgb.train(params,\n",
    "                  train_data,\n",
    "                  num_boost_round=best_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "l7ZObpkHtnUl",
    "outputId": "aa778ea0-d954-45e2-f1c9-a3b10866b8a6"
   },
   "outputs": [],
   "source": [
    "importances = model.feature_importance()\n",
    "feature_names = X_train.columns.tolist()\n",
    "importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "importance_df = importance_df.sort_values('importance', ascending=False)\n",
    "importance_df[importance_df['importance'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opcional: guardo modelo como txt\n",
    "\n",
    "# model.save_model(modelos_path + 'lgb_first.txt')\n",
    "# model = lgb.Booster(model_file=modelos_path + 'lgb_first.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Bac1TlkZjuqE"
   },
   "outputs": [],
   "source": [
    "y_pred_lgm = model.predict(X_test)\n",
    "y_pred_lgm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "iKcXUhCHlywR",
    "outputId": "cc34bc9a-be57-443c-f54f-14e585072c01"
   },
   "outputs": [],
   "source": [
    "# Supongamos que 'X_test' es tu DataFrame original del que deseas conservar el resto\n",
    "y_pred_prob = model.predict(X_test)\n",
    "\n",
    "# Convertir a predicciones binarias usando un umbral de 0.025\n",
    "threshold = 0.025\n",
    "# threshold = 0.01\n",
    "\n",
    "#probar cambiando el umbral\n",
    "y_pred_binary = (y_pred_prob >= threshold).astype(int)\n",
    "\n",
    "# Agregar las columnas de probabilidades y predicciones al DataFrame original\n",
    "X_test['probabilidad'] = y_pred_prob\n",
    "X_test['prediccion'] = y_pred_binary\n",
    "\n",
    "X_test.prediccion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "6llnHQxNoTEF",
    "outputId": "e2771427-0dd1-47ad-e6c4-e501efdd3f7f"
   },
   "outputs": [],
   "source": [
    "# Filtrar el DataFrame para quedarte solo con 'numero_de_cliente' y 'prediccion'\n",
    "result_df = X_test[['numero_de_cliente', 'prediccion']]\n",
    "\n",
    "# Renombrar la columna 'prediccion' a 'Predicted' si es necesario\n",
    "result_df.rename(columns={'prediccion': 'Predicted'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "HFD46lIRpa0F"
   },
   "outputs": [],
   "source": [
    "# Especificar la ruta completa del archivo donde deseas guardar el DataFrame\n",
    "now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "output_file = dataset_path + \"resultados_predicciones\" + now + \".csv\"\n",
    "\n",
    "print('output_file', output_file)\n",
    "\n",
    "# Guardar el DataFrame como un archivo CSV en la ruta especificada\n",
    "result_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result_df_prob = X_test[['numero_de_cliente', 'prediccion','probabilidad']]\n",
    "# Especificar la ruta completa del archivo donde deseas guardar el DataFrame\n",
    "now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "result_df_prob = dataset_path + \"resultados_predicciones_prob\" + now + \".csv\"\n",
    "\n",
    "print('result_df_prob', result_df_prob)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
